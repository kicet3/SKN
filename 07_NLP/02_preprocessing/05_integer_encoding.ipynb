{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 정수 인코딩 (Integer Encoding)\n",
    "- 자연어 처리는 텍스트 데이터를 숫자로 변환하여 컴퓨터가 이해할 수 있도록 만드는 것이 핵심\n",
    "- 정수 인코딩을 수행하여 텍스트 데이터에 고유한 인덱스를 부여 (1~5,000)\n",
    "- 이러한 인코딩 과정은 전처리 과정에서 필수적이며 각 단어의 등장 빈도에 따라 인덱스를 부여하는 것이 일반적\n",
    "- 단어 수를 5,000으로 제한하는 것은 모델 학습에 필요한 메모리와 계산 자원을 줄이기 위함 (등장 빈도가 낮은 단어는 제외하고 상위 5,000개 단어만 선택하는 것이 일반적) \n",
    "    - -> 데이터의 노이즈를 줄이고 모델의 성능 향상 가능"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "raw_text = \"\"\"The Little Prince, written by Antoine de Saint-Exupéry, is a poetic tale about a young prince who travels from his home planet to Earth. The story begins with a pilot stranded in the Sahara Desert after his plane crashes. While trying to fix his plane, he meets a mysterious young boy, the Little Prince.\n",
    "\n",
    "The Little Prince comes from a small asteroid called B-612, where he lives alone with a rose that he loves deeply. He recounts his journey to the pilot, describing his visits to several other planets. Each planet is inhabited by a different character, such as a king, a vain man, a drunkard, a businessman, a geographer, and a fox. Through these encounters, the Prince learns valuable lessons about love, responsibility, and the nature of adult behavior.\n",
    "\n",
    "On Earth, the Little Prince meets various creatures, including a fox, who teaches him about relationships and the importance of taming, which means building ties with others. The fox's famous line, \"You become responsible, forever, for what you have tamed,\" resonates with the Prince's feelings for his rose.\n",
    "\n",
    "Ultimately, the Little Prince realizes that the essence of life is often invisible and can only be seen with the heart. After sharing his wisdom with the pilot, he prepares to return to his asteroid and his beloved rose. The story concludes with the pilot reflecting on the lessons learned from the Little Prince and the enduring impact of their friendship.\n",
    "\n",
    "The narrative is a beautifully simple yet profound exploration of love, loss, and the importance of seeing beyond the surface of things.\"\"\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 인코딩 처리"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### 토큰화 + 정제/정규화"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from nltk.tokenize import sent_tokenize, word_tokenize\n",
    "from nltk.corpus import stopwords\n",
    "\n",
    "# 문장 토큰화\n",
    "sentences = sent_tokenize(raw_text)\n",
    "\n",
    "# 영문 불용어 리스트\n",
    "en_stopwords = stopwords.words('english')\n",
    "\n",
    "# 단어사전\n",
    "vocab = {}\n",
    "\n",
    "# 토큰화/정제/정규화 처리 결과\n",
    "preprocessed_sentences = []\n",
    "\n",
    "for sentence in sentences:\n",
    "    sentence = sentence.lower()         # 대소문자 정규화 (소문자 변환)\n",
    "    tokens = word_tokenize(sentence)    # 토큰화\n",
    "    tokens = [token for token in tokens if token not in en_stopwords]   # 불용어 제거\n",
    "    tokens = [token for token in tokens if len(token) > 2]    # 단어 길이가 2 이하면 제거\n",
    "\n",
    "    for token in tokens:\n",
    "        if token not in vocab:\n",
    "            vocab[token] = 1\n",
    "        else:\n",
    "            vocab[token] += 1\n",
    "            \n",
    "    preprocessed_sentences.append(tokens)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[['little',\n",
       "  'prince',\n",
       "  'written',\n",
       "  'antoine',\n",
       "  'saint-exupéry',\n",
       "  'poetic',\n",
       "  'tale',\n",
       "  'young',\n",
       "  'prince',\n",
       "  'travels',\n",
       "  'home',\n",
       "  'planet',\n",
       "  'earth'],\n",
       " ['story',\n",
       "  'begins',\n",
       "  'pilot',\n",
       "  'stranded',\n",
       "  'sahara',\n",
       "  'desert',\n",
       "  'plane',\n",
       "  'crashes'],\n",
       " ['trying',\n",
       "  'fix',\n",
       "  'plane',\n",
       "  'meets',\n",
       "  'mysterious',\n",
       "  'young',\n",
       "  'boy',\n",
       "  'little',\n",
       "  'prince'],\n",
       " ['little',\n",
       "  'prince',\n",
       "  'comes',\n",
       "  'small',\n",
       "  'asteroid',\n",
       "  'called',\n",
       "  'b-612',\n",
       "  'lives',\n",
       "  'alone',\n",
       "  'rose',\n",
       "  'loves',\n",
       "  'deeply'],\n",
       " ['recounts',\n",
       "  'journey',\n",
       "  'pilot',\n",
       "  'describing',\n",
       "  'visits',\n",
       "  'several',\n",
       "  'planets'],\n",
       " ['planet',\n",
       "  'inhabited',\n",
       "  'different',\n",
       "  'character',\n",
       "  'king',\n",
       "  'vain',\n",
       "  'man',\n",
       "  'drunkard',\n",
       "  'businessman',\n",
       "  'geographer',\n",
       "  'fox'],\n",
       " ['encounters',\n",
       "  'prince',\n",
       "  'learns',\n",
       "  'valuable',\n",
       "  'lessons',\n",
       "  'love',\n",
       "  'responsibility',\n",
       "  'nature',\n",
       "  'adult',\n",
       "  'behavior'],\n",
       " ['earth',\n",
       "  'little',\n",
       "  'prince',\n",
       "  'meets',\n",
       "  'various',\n",
       "  'creatures',\n",
       "  'including',\n",
       "  'fox',\n",
       "  'teaches',\n",
       "  'relationships',\n",
       "  'importance',\n",
       "  'taming',\n",
       "  'means',\n",
       "  'building',\n",
       "  'ties',\n",
       "  'others'],\n",
       " ['fox',\n",
       "  'famous',\n",
       "  'line',\n",
       "  'become',\n",
       "  'responsible',\n",
       "  'forever',\n",
       "  'tamed',\n",
       "  'resonates',\n",
       "  'prince',\n",
       "  'feelings',\n",
       "  'rose'],\n",
       " ['ultimately',\n",
       "  'little',\n",
       "  'prince',\n",
       "  'realizes',\n",
       "  'essence',\n",
       "  'life',\n",
       "  'often',\n",
       "  'invisible',\n",
       "  'seen',\n",
       "  'heart'],\n",
       " ['sharing',\n",
       "  'wisdom',\n",
       "  'pilot',\n",
       "  'prepares',\n",
       "  'return',\n",
       "  'asteroid',\n",
       "  'beloved',\n",
       "  'rose'],\n",
       " ['story',\n",
       "  'concludes',\n",
       "  'pilot',\n",
       "  'reflecting',\n",
       "  'lessons',\n",
       "  'learned',\n",
       "  'little',\n",
       "  'prince',\n",
       "  'enduring',\n",
       "  'impact',\n",
       "  'friendship'],\n",
       " ['narrative',\n",
       "  'beautifully',\n",
       "  'simple',\n",
       "  'yet',\n",
       "  'profound',\n",
       "  'exploration',\n",
       "  'love',\n",
       "  'loss',\n",
       "  'importance',\n",
       "  'seeing',\n",
       "  'beyond',\n",
       "  'surface',\n",
       "  'things']]"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "preprocessed_sentences"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'little': 6,\n",
       " 'prince': 9,\n",
       " 'written': 1,\n",
       " 'antoine': 1,\n",
       " 'saint-exupéry': 1,\n",
       " 'poetic': 1,\n",
       " 'tale': 1,\n",
       " 'young': 2,\n",
       " 'travels': 1,\n",
       " 'home': 1,\n",
       " 'planet': 2,\n",
       " 'earth': 2,\n",
       " 'story': 2,\n",
       " 'begins': 1,\n",
       " 'pilot': 4,\n",
       " 'stranded': 1,\n",
       " 'sahara': 1,\n",
       " 'desert': 1,\n",
       " 'plane': 2,\n",
       " 'crashes': 1,\n",
       " 'trying': 1,\n",
       " 'fix': 1,\n",
       " 'meets': 2,\n",
       " 'mysterious': 1,\n",
       " 'boy': 1,\n",
       " 'comes': 1,\n",
       " 'small': 1,\n",
       " 'asteroid': 2,\n",
       " 'called': 1,\n",
       " 'b-612': 1,\n",
       " 'lives': 1,\n",
       " 'alone': 1,\n",
       " 'rose': 3,\n",
       " 'loves': 1,\n",
       " 'deeply': 1,\n",
       " 'recounts': 1,\n",
       " 'journey': 1,\n",
       " 'describing': 1,\n",
       " 'visits': 1,\n",
       " 'several': 1,\n",
       " 'planets': 1,\n",
       " 'inhabited': 1,\n",
       " 'different': 1,\n",
       " 'character': 1,\n",
       " 'king': 1,\n",
       " 'vain': 1,\n",
       " 'man': 1,\n",
       " 'drunkard': 1,\n",
       " 'businessman': 1,\n",
       " 'geographer': 1,\n",
       " 'fox': 3,\n",
       " 'encounters': 1,\n",
       " 'learns': 1,\n",
       " 'valuable': 1,\n",
       " 'lessons': 2,\n",
       " 'love': 2,\n",
       " 'responsibility': 1,\n",
       " 'nature': 1,\n",
       " 'adult': 1,\n",
       " 'behavior': 1,\n",
       " 'various': 1,\n",
       " 'creatures': 1,\n",
       " 'including': 1,\n",
       " 'teaches': 1,\n",
       " 'relationships': 1,\n",
       " 'importance': 2,\n",
       " 'taming': 1,\n",
       " 'means': 1,\n",
       " 'building': 1,\n",
       " 'ties': 1,\n",
       " 'others': 1,\n",
       " 'famous': 1,\n",
       " 'line': 1,\n",
       " 'become': 1,\n",
       " 'responsible': 1,\n",
       " 'forever': 1,\n",
       " 'tamed': 1,\n",
       " 'resonates': 1,\n",
       " 'feelings': 1,\n",
       " 'ultimately': 1,\n",
       " 'realizes': 1,\n",
       " 'essence': 1,\n",
       " 'life': 1,\n",
       " 'often': 1,\n",
       " 'invisible': 1,\n",
       " 'seen': 1,\n",
       " 'heart': 1,\n",
       " 'sharing': 1,\n",
       " 'wisdom': 1,\n",
       " 'prepares': 1,\n",
       " 'return': 1,\n",
       " 'beloved': 1,\n",
       " 'concludes': 1,\n",
       " 'reflecting': 1,\n",
       " 'learned': 1,\n",
       " 'enduring': 1,\n",
       " 'impact': 1,\n",
       " 'friendship': 1,\n",
       " 'narrative': 1,\n",
       " 'beautifully': 1,\n",
       " 'simple': 1,\n",
       " 'yet': 1,\n",
       " 'profound': 1,\n",
       " 'exploration': 1,\n",
       " 'loss': 1,\n",
       " 'seeing': 1,\n",
       " 'beyond': 1,\n",
       " 'surface': 1,\n",
       " 'things': 1}"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "vocab"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### 빈도수 기반 정제"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('prince', 9),\n",
       " ('little', 6),\n",
       " ('pilot', 4),\n",
       " ('rose', 3),\n",
       " ('fox', 3),\n",
       " ('young', 2),\n",
       " ('planet', 2),\n",
       " ('earth', 2),\n",
       " ('story', 2),\n",
       " ('plane', 2),\n",
       " ('meets', 2),\n",
       " ('asteroid', 2),\n",
       " ('lessons', 2),\n",
       " ('love', 2),\n",
       " ('importance', 2),\n",
       " ('written', 1),\n",
       " ('antoine', 1),\n",
       " ('saint-exupéry', 1),\n",
       " ('poetic', 1),\n",
       " ('tale', 1),\n",
       " ('travels', 1),\n",
       " ('home', 1),\n",
       " ('begins', 1),\n",
       " ('stranded', 1),\n",
       " ('sahara', 1),\n",
       " ('desert', 1),\n",
       " ('crashes', 1),\n",
       " ('trying', 1),\n",
       " ('fix', 1),\n",
       " ('mysterious', 1),\n",
       " ('boy', 1),\n",
       " ('comes', 1),\n",
       " ('small', 1),\n",
       " ('called', 1),\n",
       " ('b-612', 1),\n",
       " ('lives', 1),\n",
       " ('alone', 1),\n",
       " ('loves', 1),\n",
       " ('deeply', 1),\n",
       " ('recounts', 1),\n",
       " ('journey', 1),\n",
       " ('describing', 1),\n",
       " ('visits', 1),\n",
       " ('several', 1),\n",
       " ('planets', 1),\n",
       " ('inhabited', 1),\n",
       " ('different', 1),\n",
       " ('character', 1),\n",
       " ('king', 1),\n",
       " ('vain', 1),\n",
       " ('man', 1),\n",
       " ('drunkard', 1),\n",
       " ('businessman', 1),\n",
       " ('geographer', 1),\n",
       " ('encounters', 1),\n",
       " ('learns', 1),\n",
       " ('valuable', 1),\n",
       " ('responsibility', 1),\n",
       " ('nature', 1),\n",
       " ('adult', 1),\n",
       " ('behavior', 1),\n",
       " ('various', 1),\n",
       " ('creatures', 1),\n",
       " ('including', 1),\n",
       " ('teaches', 1),\n",
       " ('relationships', 1),\n",
       " ('taming', 1),\n",
       " ('means', 1),\n",
       " ('building', 1),\n",
       " ('ties', 1),\n",
       " ('others', 1),\n",
       " ('famous', 1),\n",
       " ('line', 1),\n",
       " ('become', 1),\n",
       " ('responsible', 1),\n",
       " ('forever', 1),\n",
       " ('tamed', 1),\n",
       " ('resonates', 1),\n",
       " ('feelings', 1),\n",
       " ('ultimately', 1),\n",
       " ('realizes', 1),\n",
       " ('essence', 1),\n",
       " ('life', 1),\n",
       " ('often', 1),\n",
       " ('invisible', 1),\n",
       " ('seen', 1),\n",
       " ('heart', 1),\n",
       " ('sharing', 1),\n",
       " ('wisdom', 1),\n",
       " ('prepares', 1),\n",
       " ('return', 1),\n",
       " ('beloved', 1),\n",
       " ('concludes', 1),\n",
       " ('reflecting', 1),\n",
       " ('learned', 1),\n",
       " ('enduring', 1),\n",
       " ('impact', 1),\n",
       " ('friendship', 1),\n",
       " ('narrative', 1),\n",
       " ('beautifully', 1),\n",
       " ('simple', 1),\n",
       " ('yet', 1),\n",
       " ('profound', 1),\n",
       " ('exploration', 1),\n",
       " ('loss', 1),\n",
       " ('seeing', 1),\n",
       " ('beyond', 1),\n",
       " ('surface', 1),\n",
       " ('things', 1)]"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 빈도수 기반 역순 정렬\n",
    "vocab_sorted = sorted(vocab.items(), key=lambda item: item[1], reverse=True)\n",
    "vocab_sorted"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'prince': 1,\n",
       " 'little': 2,\n",
       " 'pilot': 3,\n",
       " 'rose': 4,\n",
       " 'fox': 5,\n",
       " 'young': 6,\n",
       " 'planet': 7,\n",
       " 'earth': 8,\n",
       " 'story': 9,\n",
       " 'plane': 10,\n",
       " 'meets': 11,\n",
       " 'asteroid': 12,\n",
       " 'lessons': 13,\n",
       " 'love': 14,\n",
       " 'importance': 15,\n",
       " 'written': 16,\n",
       " 'antoine': 17,\n",
       " 'saint-exupéry': 18,\n",
       " 'poetic': 19,\n",
       " 'tale': 20,\n",
       " 'travels': 21,\n",
       " 'home': 22,\n",
       " 'begins': 23,\n",
       " 'stranded': 24,\n",
       " 'sahara': 25,\n",
       " 'desert': 26,\n",
       " 'crashes': 27,\n",
       " 'trying': 28,\n",
       " 'fix': 29,\n",
       " 'mysterious': 30,\n",
       " 'boy': 31,\n",
       " 'comes': 32,\n",
       " 'small': 33,\n",
       " 'called': 34,\n",
       " 'b-612': 35,\n",
       " 'lives': 36,\n",
       " 'alone': 37,\n",
       " 'loves': 38,\n",
       " 'deeply': 39,\n",
       " 'recounts': 40,\n",
       " 'journey': 41,\n",
       " 'describing': 42,\n",
       " 'visits': 43,\n",
       " 'several': 44,\n",
       " 'planets': 45,\n",
       " 'inhabited': 46,\n",
       " 'different': 47,\n",
       " 'character': 48,\n",
       " 'king': 49,\n",
       " 'vain': 50,\n",
       " 'man': 51,\n",
       " 'drunkard': 52,\n",
       " 'businessman': 53,\n",
       " 'geographer': 54,\n",
       " 'encounters': 55,\n",
       " 'learns': 56,\n",
       " 'valuable': 57,\n",
       " 'responsibility': 58,\n",
       " 'nature': 59,\n",
       " 'adult': 60,\n",
       " 'behavior': 61,\n",
       " 'various': 62,\n",
       " 'creatures': 63,\n",
       " 'including': 64,\n",
       " 'teaches': 65,\n",
       " 'relationships': 66,\n",
       " 'taming': 67,\n",
       " 'means': 68,\n",
       " 'building': 69,\n",
       " 'ties': 70,\n",
       " 'others': 71,\n",
       " 'famous': 72,\n",
       " 'line': 73,\n",
       " 'become': 74,\n",
       " 'responsible': 75,\n",
       " 'forever': 76,\n",
       " 'tamed': 77,\n",
       " 'resonates': 78,\n",
       " 'feelings': 79,\n",
       " 'ultimately': 80,\n",
       " 'realizes': 81,\n",
       " 'essence': 82,\n",
       " 'life': 83,\n",
       " 'often': 84,\n",
       " 'invisible': 85,\n",
       " 'seen': 86,\n",
       " 'heart': 87,\n",
       " 'sharing': 88,\n",
       " 'wisdom': 89,\n",
       " 'prepares': 90,\n",
       " 'return': 91,\n",
       " 'beloved': 92,\n",
       " 'concludes': 93,\n",
       " 'reflecting': 94,\n",
       " 'learned': 95,\n",
       " 'enduring': 96,\n",
       " 'impact': 97,\n",
       " 'friendship': 98,\n",
       " 'narrative': 99,\n",
       " 'beautifully': 100,\n",
       " 'simple': 101,\n",
       " 'yet': 102,\n",
       " 'profound': 103,\n",
       " 'exploration': 104,\n",
       " 'loss': 105,\n",
       " 'seeing': 106,\n",
       " 'beyond': 107,\n",
       " 'surface': 108,\n",
       " 'things': 109}"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 인덱스 단어사전 생성\n",
    "word_to_index = {word: i+1 for i, (word, cnt) in enumerate(vocab_sorted)}\n",
    "word_to_index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{1: 'prince',\n",
       " 2: 'little',\n",
       " 3: 'pilot',\n",
       " 4: 'rose',\n",
       " 5: 'fox',\n",
       " 6: 'young',\n",
       " 7: 'planet',\n",
       " 8: 'earth',\n",
       " 9: 'story',\n",
       " 10: 'plane',\n",
       " 11: 'meets',\n",
       " 12: 'asteroid',\n",
       " 13: 'lessons',\n",
       " 14: 'love',\n",
       " 15: 'importance',\n",
       " 16: 'written',\n",
       " 17: 'antoine',\n",
       " 18: 'saint-exupéry',\n",
       " 19: 'poetic',\n",
       " 20: 'tale',\n",
       " 21: 'travels',\n",
       " 22: 'home',\n",
       " 23: 'begins',\n",
       " 24: 'stranded',\n",
       " 25: 'sahara',\n",
       " 26: 'desert',\n",
       " 27: 'crashes',\n",
       " 28: 'trying',\n",
       " 29: 'fix',\n",
       " 30: 'mysterious',\n",
       " 31: 'boy',\n",
       " 32: 'comes',\n",
       " 33: 'small',\n",
       " 34: 'called',\n",
       " 35: 'b-612',\n",
       " 36: 'lives',\n",
       " 37: 'alone',\n",
       " 38: 'loves',\n",
       " 39: 'deeply',\n",
       " 40: 'recounts',\n",
       " 41: 'journey',\n",
       " 42: 'describing',\n",
       " 43: 'visits',\n",
       " 44: 'several',\n",
       " 45: 'planets',\n",
       " 46: 'inhabited',\n",
       " 47: 'different',\n",
       " 48: 'character',\n",
       " 49: 'king',\n",
       " 50: 'vain',\n",
       " 51: 'man',\n",
       " 52: 'drunkard',\n",
       " 53: 'businessman',\n",
       " 54: 'geographer',\n",
       " 55: 'encounters',\n",
       " 56: 'learns',\n",
       " 57: 'valuable',\n",
       " 58: 'responsibility',\n",
       " 59: 'nature',\n",
       " 60: 'adult',\n",
       " 61: 'behavior',\n",
       " 62: 'various',\n",
       " 63: 'creatures',\n",
       " 64: 'including',\n",
       " 65: 'teaches',\n",
       " 66: 'relationships',\n",
       " 67: 'taming',\n",
       " 68: 'means',\n",
       " 69: 'building',\n",
       " 70: 'ties',\n",
       " 71: 'others',\n",
       " 72: 'famous',\n",
       " 73: 'line',\n",
       " 74: 'become',\n",
       " 75: 'responsible',\n",
       " 76: 'forever',\n",
       " 77: 'tamed',\n",
       " 78: 'resonates',\n",
       " 79: 'feelings',\n",
       " 80: 'ultimately',\n",
       " 81: 'realizes',\n",
       " 82: 'essence',\n",
       " 83: 'life',\n",
       " 84: 'often',\n",
       " 85: 'invisible',\n",
       " 86: 'seen',\n",
       " 87: 'heart',\n",
       " 88: 'sharing',\n",
       " 89: 'wisdom',\n",
       " 90: 'prepares',\n",
       " 91: 'return',\n",
       " 92: 'beloved',\n",
       " 93: 'concludes',\n",
       " 94: 'reflecting',\n",
       " 95: 'learned',\n",
       " 96: 'enduring',\n",
       " 97: 'impact',\n",
       " 98: 'friendship',\n",
       " 99: 'narrative',\n",
       " 100: 'beautifully',\n",
       " 101: 'simple',\n",
       " 102: 'yet',\n",
       " 103: 'profound',\n",
       " 104: 'exploration',\n",
       " 105: 'loss',\n",
       " 106: 'seeing',\n",
       " 107: 'beyond',\n",
       " 108: 'surface',\n",
       " 109: 'things'}"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 인덱스 단어사전2 생성\n",
    "index_to_word = {i+1: word for i, (word, cnt) in enumerate(vocab_sorted)}\n",
    "index_to_word"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'prince': 1,\n",
       " 'little': 2,\n",
       " 'pilot': 3,\n",
       " 'rose': 4,\n",
       " 'fox': 5,\n",
       " 'young': 6,\n",
       " 'planet': 7,\n",
       " 'earth': 8,\n",
       " 'story': 9,\n",
       " 'plane': 10,\n",
       " 'meets': 11,\n",
       " 'asteroid': 12,\n",
       " 'lessons': 13,\n",
       " 'love': 14,\n",
       " 'importance': 15}"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "vocab_size = 15\n",
    "word_to_index = {word: index for word, index in word_to_index.items() if index <= vocab_size}\n",
    "word_to_index"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### OOV 처리"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**OOV(Out of vocabulary)** : 단어사전에 정의되지 않은 단어를 가르키는 키워드"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'prince': 1,\n",
       " 'little': 2,\n",
       " 'pilot': 3,\n",
       " 'rose': 4,\n",
       " 'fox': 5,\n",
       " 'young': 6,\n",
       " 'planet': 7,\n",
       " 'earth': 8,\n",
       " 'story': 9,\n",
       " 'plane': 10,\n",
       " 'meets': 11,\n",
       " 'asteroid': 12,\n",
       " 'lessons': 13,\n",
       " 'love': 14,\n",
       " 'importance': 15,\n",
       " 'OOV': 16}"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "word_to_index['OOV'] = len(word_to_index) + 1\n",
    "word_to_index"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### 수열처리 (=정수 인코딩)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['little', 'prince', 'written', 'antoine', 'saint-exupéry', 'poetic', 'tale', 'young', 'prince', 'travels', 'home', 'planet', 'earth']\n",
      "[2, 1, 16, 16, 16, 16, 16, 6, 1, 16, 16, 7, 8]\n",
      "\n",
      "['story', 'begins', 'pilot', 'stranded', 'sahara', 'desert', 'plane', 'crashes']\n",
      "[9, 16, 3, 16, 16, 16, 10, 16]\n",
      "\n",
      "['trying', 'fix', 'plane', 'meets', 'mysterious', 'young', 'boy', 'little', 'prince']\n",
      "[16, 16, 10, 11, 16, 6, 16, 2, 1]\n",
      "\n",
      "['little', 'prince', 'comes', 'small', 'asteroid', 'called', 'b-612', 'lives', 'alone', 'rose', 'loves', 'deeply']\n",
      "[2, 1, 16, 16, 12, 16, 16, 16, 16, 4, 16, 16]\n",
      "\n",
      "['recounts', 'journey', 'pilot', 'describing', 'visits', 'several', 'planets']\n",
      "[16, 16, 3, 16, 16, 16, 16]\n",
      "\n",
      "['planet', 'inhabited', 'different', 'character', 'king', 'vain', 'man', 'drunkard', 'businessman', 'geographer', 'fox']\n",
      "[7, 16, 16, 16, 16, 16, 16, 16, 16, 16, 5]\n",
      "\n",
      "['encounters', 'prince', 'learns', 'valuable', 'lessons', 'love', 'responsibility', 'nature', 'adult', 'behavior']\n",
      "[16, 1, 16, 16, 13, 14, 16, 16, 16, 16]\n",
      "\n",
      "['earth', 'little', 'prince', 'meets', 'various', 'creatures', 'including', 'fox', 'teaches', 'relationships', 'importance', 'taming', 'means', 'building', 'ties', 'others']\n",
      "[8, 2, 1, 11, 16, 16, 16, 5, 16, 16, 15, 16, 16, 16, 16, 16]\n",
      "\n",
      "['fox', 'famous', 'line', 'become', 'responsible', 'forever', 'tamed', 'resonates', 'prince', 'feelings', 'rose']\n",
      "[5, 16, 16, 16, 16, 16, 16, 16, 1, 16, 4]\n",
      "\n",
      "['ultimately', 'little', 'prince', 'realizes', 'essence', 'life', 'often', 'invisible', 'seen', 'heart']\n",
      "[16, 2, 1, 16, 16, 16, 16, 16, 16, 16]\n",
      "\n",
      "['sharing', 'wisdom', 'pilot', 'prepares', 'return', 'asteroid', 'beloved', 'rose']\n",
      "[16, 16, 3, 16, 16, 12, 16, 4]\n",
      "\n",
      "['story', 'concludes', 'pilot', 'reflecting', 'lessons', 'learned', 'little', 'prince', 'enduring', 'impact', 'friendship']\n",
      "[9, 16, 3, 16, 13, 16, 2, 1, 16, 16, 16]\n",
      "\n",
      "['narrative', 'beautifully', 'simple', 'yet', 'profound', 'exploration', 'love', 'loss', 'importance', 'seeing', 'beyond', 'surface', 'things']\n",
      "[16, 16, 16, 16, 16, 16, 14, 16, 15, 16, 16, 16, 16]\n",
      "\n"
     ]
    }
   ],
   "source": [
    "encoded_sentences = []\n",
    "oov_idx = word_to_index['OOV']\n",
    "\n",
    "for sentence in preprocessed_sentences:\n",
    "    encoded_sentence = [word_to_index.get(token, oov_idx) for token in sentence]\n",
    "    print(sentence)\n",
    "    print(encoded_sentence)\n",
    "    print()\n",
    "    encoded_sentences.append(encoded_sentence)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### keras Tokenizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting tensorflow\n",
      "  Downloading tensorflow-2.19.0-cp312-cp312-win_amd64.whl.metadata (4.1 kB)\n",
      "Collecting absl-py>=1.0.0 (from tensorflow)\n",
      "  Downloading absl_py-2.2.2-py3-none-any.whl.metadata (2.6 kB)\n",
      "Collecting astunparse>=1.6.0 (from tensorflow)\n",
      "  Downloading astunparse-1.6.3-py2.py3-none-any.whl.metadata (4.4 kB)\n",
      "Collecting flatbuffers>=24.3.25 (from tensorflow)\n",
      "  Downloading flatbuffers-25.2.10-py2.py3-none-any.whl.metadata (875 bytes)\n",
      "Collecting gast!=0.5.0,!=0.5.1,!=0.5.2,>=0.2.1 (from tensorflow)\n",
      "  Downloading gast-0.6.0-py3-none-any.whl.metadata (1.3 kB)\n",
      "Collecting google-pasta>=0.1.1 (from tensorflow)\n",
      "  Downloading google_pasta-0.2.0-py3-none-any.whl.metadata (814 bytes)\n",
      "Collecting libclang>=13.0.0 (from tensorflow)\n",
      "  Downloading libclang-18.1.1-py2.py3-none-win_amd64.whl.metadata (5.3 kB)\n",
      "Collecting opt-einsum>=2.3.2 (from tensorflow)\n",
      "  Downloading opt_einsum-3.4.0-py3-none-any.whl.metadata (6.3 kB)\n",
      "Requirement already satisfied: packaging in c:\\users\\playdata\\anaconda3\\envs\\pystudy_env\\lib\\site-packages (from tensorflow) (24.2)\n",
      "Requirement already satisfied: protobuf!=4.21.0,!=4.21.1,!=4.21.2,!=4.21.3,!=4.21.4,!=4.21.5,<6.0.0dev,>=3.20.3 in c:\\users\\playdata\\anaconda3\\envs\\pystudy_env\\lib\\site-packages (from tensorflow) (5.29.3)\n",
      "Requirement already satisfied: requests<3,>=2.21.0 in c:\\users\\playdata\\anaconda3\\envs\\pystudy_env\\lib\\site-packages (from tensorflow) (2.32.3)\n",
      "Requirement already satisfied: setuptools in c:\\users\\playdata\\anaconda3\\envs\\pystudy_env\\lib\\site-packages (from tensorflow) (75.8.0)\n",
      "Requirement already satisfied: six>=1.12.0 in c:\\users\\playdata\\anaconda3\\envs\\pystudy_env\\lib\\site-packages (from tensorflow) (1.17.0)\n",
      "Collecting termcolor>=1.1.0 (from tensorflow)\n",
      "  Downloading termcolor-3.0.1-py3-none-any.whl.metadata (6.1 kB)\n",
      "Requirement already satisfied: typing-extensions>=3.6.6 in c:\\users\\playdata\\anaconda3\\envs\\pystudy_env\\lib\\site-packages (from tensorflow) (4.12.2)\n",
      "Requirement already satisfied: wrapt>=1.11.0 in c:\\users\\playdata\\anaconda3\\envs\\pystudy_env\\lib\\site-packages (from tensorflow) (1.17.2)\n",
      "Collecting grpcio<2.0,>=1.24.3 (from tensorflow)\n",
      "  Downloading grpcio-1.71.0-cp312-cp312-win_amd64.whl.metadata (4.0 kB)\n",
      "Collecting tensorboard~=2.19.0 (from tensorflow)\n",
      "  Downloading tensorboard-2.19.0-py3-none-any.whl.metadata (1.8 kB)\n",
      "Collecting keras>=3.5.0 (from tensorflow)\n",
      "  Downloading keras-3.9.2-py3-none-any.whl.metadata (6.1 kB)\n",
      "Requirement already satisfied: numpy<2.2.0,>=1.26.0 in c:\\users\\playdata\\anaconda3\\envs\\pystudy_env\\lib\\site-packages (from tensorflow) (1.26.4)\n",
      "Collecting h5py>=3.11.0 (from tensorflow)\n",
      "  Downloading h5py-3.13.0-cp312-cp312-win_amd64.whl.metadata (2.5 kB)\n",
      "Collecting ml-dtypes<1.0.0,>=0.5.1 (from tensorflow)\n",
      "  Downloading ml_dtypes-0.5.1-cp312-cp312-win_amd64.whl.metadata (22 kB)\n",
      "Requirement already satisfied: wheel<1.0,>=0.23.0 in c:\\users\\playdata\\anaconda3\\envs\\pystudy_env\\lib\\site-packages (from astunparse>=1.6.0->tensorflow) (0.45.1)\n",
      "Requirement already satisfied: rich in c:\\users\\playdata\\anaconda3\\envs\\pystudy_env\\lib\\site-packages (from keras>=3.5.0->tensorflow) (13.9.4)\n",
      "Collecting namex (from keras>=3.5.0->tensorflow)\n",
      "  Downloading namex-0.0.8-py3-none-any.whl.metadata (246 bytes)\n",
      "Collecting optree (from keras>=3.5.0->tensorflow)\n",
      "  Downloading optree-0.14.1-cp312-cp312-win_amd64.whl.metadata (50 kB)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in c:\\users\\playdata\\anaconda3\\envs\\pystudy_env\\lib\\site-packages (from requests<3,>=2.21.0->tensorflow) (3.4.1)\n",
      "Requirement already satisfied: idna<4,>=2.5 in c:\\users\\playdata\\anaconda3\\envs\\pystudy_env\\lib\\site-packages (from requests<3,>=2.21.0->tensorflow) (3.10)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in c:\\users\\playdata\\anaconda3\\envs\\pystudy_env\\lib\\site-packages (from requests<3,>=2.21.0->tensorflow) (2.3.0)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in c:\\users\\playdata\\anaconda3\\envs\\pystudy_env\\lib\\site-packages (from requests<3,>=2.21.0->tensorflow) (2025.1.31)\n",
      "Collecting markdown>=2.6.8 (from tensorboard~=2.19.0->tensorflow)\n",
      "  Downloading Markdown-3.7-py3-none-any.whl.metadata (7.0 kB)\n",
      "Collecting tensorboard-data-server<0.8.0,>=0.7.0 (from tensorboard~=2.19.0->tensorflow)\n",
      "  Downloading tensorboard_data_server-0.7.2-py3-none-any.whl.metadata (1.1 kB)\n",
      "Collecting werkzeug>=1.0.1 (from tensorboard~=2.19.0->tensorflow)\n",
      "  Downloading werkzeug-3.1.3-py3-none-any.whl.metadata (3.7 kB)\n",
      "Requirement already satisfied: MarkupSafe>=2.1.1 in c:\\users\\playdata\\anaconda3\\envs\\pystudy_env\\lib\\site-packages (from werkzeug>=1.0.1->tensorboard~=2.19.0->tensorflow) (3.0.2)\n",
      "Requirement already satisfied: markdown-it-py>=2.2.0 in c:\\users\\playdata\\anaconda3\\envs\\pystudy_env\\lib\\site-packages (from rich->keras>=3.5.0->tensorflow) (3.0.0)\n",
      "Requirement already satisfied: pygments<3.0.0,>=2.13.0 in c:\\users\\playdata\\anaconda3\\envs\\pystudy_env\\lib\\site-packages (from rich->keras>=3.5.0->tensorflow) (2.19.1)\n",
      "Requirement already satisfied: mdurl~=0.1 in c:\\users\\playdata\\anaconda3\\envs\\pystudy_env\\lib\\site-packages (from markdown-it-py>=2.2.0->rich->keras>=3.5.0->tensorflow) (0.1.2)\n",
      "Downloading tensorflow-2.19.0-cp312-cp312-win_amd64.whl (376.0 MB)\n",
      "   ---------------------------------------- 0.0/376.0 MB ? eta -:--:--\n",
      "   ---------------------------------------- 3.4/376.0 MB 18.3 MB/s eta 0:00:21\n",
      "    --------------------------------------- 7.6/376.0 MB 18.8 MB/s eta 0:00:20\n",
      "   - -------------------------------------- 11.5/376.0 MB 19.0 MB/s eta 0:00:20\n",
      "   - -------------------------------------- 17.0/376.0 MB 20.6 MB/s eta 0:00:18\n",
      "   -- ------------------------------------- 21.8/376.0 MB 20.8 MB/s eta 0:00:18\n",
      "   -- ------------------------------------- 25.2/376.0 MB 20.4 MB/s eta 0:00:18\n",
      "   --- ------------------------------------ 29.1/376.0 MB 19.8 MB/s eta 0:00:18\n",
      "   --- ------------------------------------ 33.0/376.0 MB 19.6 MB/s eta 0:00:18\n",
      "   ---- ----------------------------------- 37.7/376.0 MB 20.0 MB/s eta 0:00:17\n",
      "   ---- ----------------------------------- 40.9/376.0 MB 19.4 MB/s eta 0:00:18\n",
      "   ---- ----------------------------------- 44.8/376.0 MB 19.3 MB/s eta 0:00:18\n",
      "   ----- ---------------------------------- 48.5/376.0 MB 19.2 MB/s eta 0:00:18\n",
      "   ----- ---------------------------------- 51.6/376.0 MB 18.8 MB/s eta 0:00:18\n",
      "   ----- ---------------------------------- 56.1/376.0 MB 18.9 MB/s eta 0:00:17\n",
      "   ------ --------------------------------- 59.5/376.0 MB 18.8 MB/s eta 0:00:17\n",
      "   ------ --------------------------------- 63.4/376.0 MB 18.8 MB/s eta 0:00:17\n",
      "   ------- -------------------------------- 66.6/376.0 MB 18.6 MB/s eta 0:00:17\n",
      "   ------- -------------------------------- 71.0/376.0 MB 18.6 MB/s eta 0:00:17\n",
      "   ------- -------------------------------- 73.1/376.0 MB 18.2 MB/s eta 0:00:17\n",
      "   -------- ------------------------------- 76.5/376.0 MB 18.1 MB/s eta 0:00:17\n",
      "   -------- ------------------------------- 80.2/376.0 MB 18.1 MB/s eta 0:00:17\n",
      "   --------- ------------------------------ 85.2/376.0 MB 18.2 MB/s eta 0:00:16\n",
      "   --------- ------------------------------ 89.9/376.0 MB 18.4 MB/s eta 0:00:16\n",
      "   ---------- ----------------------------- 94.6/376.0 MB 18.6 MB/s eta 0:00:16\n",
      "   ---------- ----------------------------- 98.8/376.0 MB 18.6 MB/s eta 0:00:15\n",
      "   ---------- ---------------------------- 102.5/376.0 MB 18.6 MB/s eta 0:00:15\n",
      "   ----------- --------------------------- 106.2/376.0 MB 18.6 MB/s eta 0:00:15\n",
      "   ----------- --------------------------- 109.6/376.0 MB 18.5 MB/s eta 0:00:15\n",
      "   ----------- --------------------------- 113.2/376.0 MB 18.4 MB/s eta 0:00:15\n",
      "   ----------- --------------------------- 113.8/376.0 MB 18.0 MB/s eta 0:00:15\n",
      "   ------------ -------------------------- 116.9/376.0 MB 17.8 MB/s eta 0:00:15\n",
      "   ------------ -------------------------- 121.4/376.0 MB 17.9 MB/s eta 0:00:15\n",
      "   ------------ -------------------------- 125.0/376.0 MB 17.9 MB/s eta 0:00:15\n",
      "   ------------- ------------------------- 126.1/376.0 MB 17.5 MB/s eta 0:00:15\n",
      "   ------------- ------------------------- 129.0/376.0 MB 17.5 MB/s eta 0:00:15\n",
      "   ------------- ------------------------- 132.4/376.0 MB 17.4 MB/s eta 0:00:15\n",
      "   -------------- ------------------------ 135.3/376.0 MB 17.2 MB/s eta 0:00:14\n",
      "   -------------- ------------------------ 139.2/376.0 MB 17.3 MB/s eta 0:00:14\n",
      "   -------------- ------------------------ 144.2/376.0 MB 17.4 MB/s eta 0:00:14\n",
      "   --------------- ----------------------- 148.9/376.0 MB 17.6 MB/s eta 0:00:13\n",
      "   --------------- ----------------------- 153.6/376.0 MB 17.7 MB/s eta 0:00:13\n",
      "   ---------------- ---------------------- 156.8/376.0 MB 17.6 MB/s eta 0:00:13\n",
      "   ---------------- ---------------------- 160.7/376.0 MB 17.6 MB/s eta 0:00:13\n",
      "   ----------------- --------------------- 165.7/376.0 MB 17.8 MB/s eta 0:00:12\n",
      "   ----------------- --------------------- 170.9/376.0 MB 17.9 MB/s eta 0:00:12\n",
      "   ------------------ -------------------- 174.9/376.0 MB 18.0 MB/s eta 0:00:12\n",
      "   ------------------ -------------------- 179.6/376.0 MB 18.1 MB/s eta 0:00:11\n",
      "   ------------------- ------------------- 184.3/376.0 MB 18.1 MB/s eta 0:00:11\n",
      "   ------------------- ------------------- 187.7/376.0 MB 18.1 MB/s eta 0:00:11\n",
      "   ------------------- ------------------- 189.0/376.0 MB 17.9 MB/s eta 0:00:11\n",
      "   ------------------- ------------------- 191.1/376.0 MB 17.8 MB/s eta 0:00:11\n",
      "   ------------------- ------------------- 192.7/376.0 MB 17.6 MB/s eta 0:00:11\n",
      "   -------------------- ------------------ 194.8/376.0 MB 17.4 MB/s eta 0:00:11\n",
      "   -------------------- ------------------ 196.6/376.0 MB 17.2 MB/s eta 0:00:11\n",
      "   -------------------- ------------------ 199.5/376.0 MB 17.1 MB/s eta 0:00:11\n",
      "   -------------------- ------------------ 201.9/376.0 MB 17.0 MB/s eta 0:00:11\n",
      "   --------------------- ----------------- 204.5/376.0 MB 17.0 MB/s eta 0:00:11\n",
      "   --------------------- ----------------- 207.1/376.0 MB 16.9 MB/s eta 0:00:11\n",
      "   --------------------- ----------------- 209.5/376.0 MB 16.8 MB/s eta 0:00:10\n",
      "   --------------------- ----------------- 211.6/376.0 MB 16.7 MB/s eta 0:00:10\n",
      "   ---------------------- ---------------- 214.7/376.0 MB 16.6 MB/s eta 0:00:10\n",
      "   ---------------------- ---------------- 216.8/376.0 MB 16.5 MB/s eta 0:00:10\n",
      "   ---------------------- ---------------- 217.8/376.0 MB 16.4 MB/s eta 0:00:10\n",
      "   ---------------------- ---------------- 218.6/376.0 MB 16.1 MB/s eta 0:00:10\n",
      "   ---------------------- ---------------- 221.0/376.0 MB 16.1 MB/s eta 0:00:10\n",
      "   ----------------------- --------------- 222.6/376.0 MB 15.9 MB/s eta 0:00:10\n",
      "   ----------------------- --------------- 223.3/376.0 MB 15.8 MB/s eta 0:00:10\n",
      "   ----------------------- --------------- 224.1/376.0 MB 15.6 MB/s eta 0:00:10\n",
      "   ----------------------- --------------- 224.7/376.0 MB 15.4 MB/s eta 0:00:10\n",
      "   ----------------------- --------------- 226.0/376.0 MB 15.3 MB/s eta 0:00:10\n",
      "   ----------------------- --------------- 227.8/376.0 MB 15.2 MB/s eta 0:00:10\n",
      "   ----------------------- --------------- 228.9/376.0 MB 15.0 MB/s eta 0:00:10\n",
      "   ----------------------- --------------- 229.6/376.0 MB 14.9 MB/s eta 0:00:10\n",
      "   ----------------------- --------------- 230.9/376.0 MB 14.7 MB/s eta 0:00:10\n",
      "   ------------------------ -------------- 231.7/376.0 MB 14.6 MB/s eta 0:00:10\n",
      "   ------------------------ -------------- 232.8/376.0 MB 14.5 MB/s eta 0:00:10\n",
      "   ------------------------ -------------- 233.3/376.0 MB 14.3 MB/s eta 0:00:10\n",
      "   ------------------------ -------------- 234.4/376.0 MB 14.2 MB/s eta 0:00:10\n",
      "   ------------------------ -------------- 235.1/376.0 MB 14.1 MB/s eta 0:00:11\n",
      "   ------------------------ -------------- 235.9/376.0 MB 13.9 MB/s eta 0:00:11\n",
      "   ------------------------ -------------- 236.5/376.0 MB 13.8 MB/s eta 0:00:11\n",
      "   ------------------------ -------------- 237.5/376.0 MB 13.7 MB/s eta 0:00:11\n",
      "   ------------------------ -------------- 239.1/376.0 MB 13.6 MB/s eta 0:00:11\n",
      "   ------------------------ -------------- 239.6/376.0 MB 13.5 MB/s eta 0:00:11\n",
      "   ------------------------ -------------- 240.1/376.0 MB 13.4 MB/s eta 0:00:11\n",
      "   ------------------------ -------------- 240.6/376.0 MB 13.2 MB/s eta 0:00:11\n",
      "   ------------------------ -------------- 240.9/376.0 MB 13.1 MB/s eta 0:00:11\n",
      "   ------------------------- ------------- 241.4/376.0 MB 13.0 MB/s eta 0:00:11\n",
      "   ------------------------- ------------- 241.7/376.0 MB 12.9 MB/s eta 0:00:11\n",
      "   ------------------------- ------------- 242.0/376.0 MB 12.7 MB/s eta 0:00:11\n",
      "   ------------------------- ------------- 242.2/376.0 MB 12.7 MB/s eta 0:00:11\n",
      "   ------------------------- ------------- 243.0/376.0 MB 12.5 MB/s eta 0:00:11\n",
      "   ------------------------- ------------- 243.8/376.0 MB 12.4 MB/s eta 0:00:11\n",
      "   ------------------------- ------------- 244.8/376.0 MB 12.3 MB/s eta 0:00:11\n",
      "   ------------------------- ------------- 245.9/376.0 MB 12.2 MB/s eta 0:00:11\n",
      "   ------------------------- ------------- 246.4/376.0 MB 12.1 MB/s eta 0:00:11\n",
      "   ------------------------- ------------- 247.2/376.0 MB 12.0 MB/s eta 0:00:11\n",
      "   ------------------------- ------------- 248.3/376.0 MB 12.0 MB/s eta 0:00:11\n",
      "   ------------------------- ------------- 248.8/376.0 MB 11.9 MB/s eta 0:00:11\n",
      "   ------------------------- ------------- 249.0/376.0 MB 11.8 MB/s eta 0:00:11\n",
      "   ------------------------- ------------- 249.8/376.0 MB 11.7 MB/s eta 0:00:11\n",
      "   ------------------------- ------------- 250.6/376.0 MB 11.6 MB/s eta 0:00:11\n",
      "   -------------------------- ------------ 250.9/376.0 MB 11.6 MB/s eta 0:00:11\n",
      "   -------------------------- ------------ 251.7/376.0 MB 11.4 MB/s eta 0:00:11\n",
      "   -------------------------- ------------ 252.2/376.0 MB 11.4 MB/s eta 0:00:11\n",
      "   -------------------------- ------------ 253.5/376.0 MB 11.3 MB/s eta 0:00:11\n",
      "   -------------------------- ------------ 254.3/376.0 MB 11.3 MB/s eta 0:00:11\n",
      "   -------------------------- ------------ 255.3/376.0 MB 11.2 MB/s eta 0:00:11\n",
      "   -------------------------- ------------ 256.4/376.0 MB 11.1 MB/s eta 0:00:11\n",
      "   -------------------------- ------------ 257.9/376.0 MB 11.1 MB/s eta 0:00:11\n",
      "   -------------------------- ------------ 258.7/376.0 MB 11.0 MB/s eta 0:00:11\n",
      "   -------------------------- ------------ 259.5/376.0 MB 11.0 MB/s eta 0:00:11\n",
      "   --------------------------- ----------- 260.3/376.0 MB 10.9 MB/s eta 0:00:11\n",
      "   --------------------------- ----------- 261.1/376.0 MB 10.8 MB/s eta 0:00:11\n",
      "   --------------------------- ----------- 261.9/376.0 MB 10.8 MB/s eta 0:00:11\n",
      "   --------------------------- ----------- 261.9/376.0 MB 10.8 MB/s eta 0:00:11\n",
      "   --------------------------- ----------- 262.4/376.0 MB 10.6 MB/s eta 0:00:11\n",
      "   --------------------------- ----------- 263.5/376.0 MB 10.5 MB/s eta 0:00:11\n",
      "   --------------------------- ----------- 264.5/376.0 MB 10.4 MB/s eta 0:00:11\n",
      "   --------------------------- ----------- 265.6/376.0 MB 10.4 MB/s eta 0:00:11\n",
      "   --------------------------- ----------- 266.1/376.0 MB 10.4 MB/s eta 0:00:11\n",
      "   --------------------------- ----------- 266.6/376.0 MB 10.3 MB/s eta 0:00:11\n",
      "   --------------------------- ----------- 266.9/376.0 MB 10.2 MB/s eta 0:00:11\n",
      "   --------------------------- ----------- 268.2/376.0 MB 10.1 MB/s eta 0:00:11\n",
      "   --------------------------- ----------- 269.5/376.0 MB 10.1 MB/s eta 0:00:11\n",
      "   ---------------------------- ---------- 270.5/376.0 MB 10.0 MB/s eta 0:00:11\n",
      "   ---------------------------- ----------- 271.6/376.0 MB 9.9 MB/s eta 0:00:11\n",
      "   ----------------------------- ---------- 272.9/376.0 MB 9.9 MB/s eta 0:00:11\n",
      "   ----------------------------- ---------- 273.9/376.0 MB 9.8 MB/s eta 0:00:11\n",
      "   ----------------------------- ---------- 274.7/376.0 MB 9.8 MB/s eta 0:00:11\n",
      "   ----------------------------- ---------- 275.3/376.0 MB 9.7 MB/s eta 0:00:11\n",
      "   ----------------------------- ---------- 276.0/376.0 MB 9.6 MB/s eta 0:00:11\n",
      "   ----------------------------- ---------- 276.8/376.0 MB 9.6 MB/s eta 0:00:11\n",
      "   ----------------------------- ---------- 277.6/376.0 MB 9.5 MB/s eta 0:00:11\n",
      "   ----------------------------- ---------- 278.1/376.0 MB 9.5 MB/s eta 0:00:11\n",
      "   ----------------------------- ---------- 278.7/376.0 MB 9.4 MB/s eta 0:00:11\n",
      "   ----------------------------- ---------- 279.2/376.0 MB 9.3 MB/s eta 0:00:11\n",
      "   ----------------------------- ---------- 280.0/376.0 MB 9.3 MB/s eta 0:00:11\n",
      "   ----------------------------- ---------- 281.0/376.0 MB 9.2 MB/s eta 0:00:11\n",
      "   ----------------------------- ---------- 281.5/376.0 MB 9.2 MB/s eta 0:00:11\n",
      "   ------------------------------ --------- 282.1/376.0 MB 9.1 MB/s eta 0:00:11\n",
      "   ------------------------------ --------- 282.9/376.0 MB 9.1 MB/s eta 0:00:11\n",
      "   ------------------------------ --------- 283.6/376.0 MB 9.0 MB/s eta 0:00:11\n",
      "   ------------------------------ --------- 284.4/376.0 MB 8.9 MB/s eta 0:00:11\n",
      "   ------------------------------ --------- 284.7/376.0 MB 8.9 MB/s eta 0:00:11\n",
      "   ------------------------------ --------- 285.5/376.0 MB 8.8 MB/s eta 0:00:11\n",
      "   ------------------------------ --------- 286.5/376.0 MB 8.8 MB/s eta 0:00:11\n",
      "   ------------------------------ --------- 287.3/376.0 MB 8.8 MB/s eta 0:00:11\n",
      "   ------------------------------ --------- 287.8/376.0 MB 8.7 MB/s eta 0:00:11\n",
      "   ------------------------------ --------- 288.6/376.0 MB 8.6 MB/s eta 0:00:11\n",
      "   ------------------------------ --------- 289.7/376.0 MB 8.5 MB/s eta 0:00:11\n",
      "   ------------------------------ --------- 290.5/376.0 MB 8.4 MB/s eta 0:00:11\n",
      "   ------------------------------ --------- 291.2/376.0 MB 8.3 MB/s eta 0:00:11\n",
      "   ------------------------------- -------- 291.5/376.0 MB 8.2 MB/s eta 0:00:11\n",
      "   ------------------------------- -------- 292.0/376.0 MB 8.1 MB/s eta 0:00:11\n",
      "   ------------------------------- -------- 292.6/376.0 MB 8.0 MB/s eta 0:00:11\n",
      "   ------------------------------- -------- 293.6/376.0 MB 7.9 MB/s eta 0:00:11\n",
      "   ------------------------------- -------- 294.1/376.0 MB 7.8 MB/s eta 0:00:11\n",
      "   ------------------------------- -------- 294.9/376.0 MB 7.7 MB/s eta 0:00:11\n",
      "   ------------------------------- -------- 295.2/376.0 MB 7.7 MB/s eta 0:00:11\n",
      "   ------------------------------- -------- 295.4/376.0 MB 7.5 MB/s eta 0:00:11\n",
      "   ------------------------------- -------- 296.0/376.0 MB 7.4 MB/s eta 0:00:11\n",
      "   ------------------------------- -------- 297.0/376.0 MB 7.3 MB/s eta 0:00:11\n",
      "   ------------------------------- -------- 298.3/376.0 MB 7.2 MB/s eta 0:00:11\n",
      "   ------------------------------- -------- 299.1/376.0 MB 7.1 MB/s eta 0:00:11\n",
      "   ------------------------------- -------- 300.2/376.0 MB 7.0 MB/s eta 0:00:11\n",
      "   -------------------------------- ------- 301.2/376.0 MB 6.8 MB/s eta 0:00:11\n",
      "   -------------------------------- ------- 301.5/376.0 MB 6.8 MB/s eta 0:00:12\n",
      "   -------------------------------- ------- 302.8/376.0 MB 6.6 MB/s eta 0:00:12\n",
      "   -------------------------------- ------- 303.6/376.0 MB 6.6 MB/s eta 0:00:12\n",
      "   -------------------------------- ------- 304.3/376.0 MB 6.4 MB/s eta 0:00:12\n",
      "   -------------------------------- ------- 304.9/376.0 MB 6.4 MB/s eta 0:00:12\n",
      "   -------------------------------- ------- 305.1/376.0 MB 6.4 MB/s eta 0:00:12\n",
      "   -------------------------------- ------- 305.1/376.0 MB 6.4 MB/s eta 0:00:12\n",
      "   -------------------------------- ------- 305.9/376.0 MB 6.1 MB/s eta 0:00:12\n",
      "   -------------------------------- ------- 306.2/376.0 MB 6.1 MB/s eta 0:00:12\n",
      "   -------------------------------- ------- 306.4/376.0 MB 6.0 MB/s eta 0:00:12\n",
      "   -------------------------------- ------- 308.3/376.0 MB 5.9 MB/s eta 0:00:12\n",
      "   -------------------------------- ------- 309.9/376.0 MB 5.9 MB/s eta 0:00:12\n",
      "   --------------------------------- ------ 311.4/376.0 MB 5.8 MB/s eta 0:00:12\n",
      "   --------------------------------- ------ 313.3/376.0 MB 5.8 MB/s eta 0:00:11\n",
      "   --------------------------------- ------ 315.1/376.0 MB 5.7 MB/s eta 0:00:11\n",
      "   --------------------------------- ------ 316.1/376.0 MB 5.5 MB/s eta 0:00:11\n",
      "   --------------------------------- ------ 319.3/376.0 MB 5.5 MB/s eta 0:00:11\n",
      "   ---------------------------------- ----- 320.6/376.0 MB 5.4 MB/s eta 0:00:11\n",
      "   ---------------------------------- ----- 324.3/376.0 MB 5.4 MB/s eta 0:00:10\n",
      "   ---------------------------------- ----- 326.9/376.0 MB 5.4 MB/s eta 0:00:10\n",
      "   ----------------------------------- ---- 329.5/376.0 MB 5.3 MB/s eta 0:00:09\n",
      "   ----------------------------------- ---- 331.9/376.0 MB 5.2 MB/s eta 0:00:09\n",
      "   ----------------------------------- ---- 334.8/376.0 MB 5.2 MB/s eta 0:00:08\n",
      "   ----------------------------------- ---- 337.6/376.0 MB 5.1 MB/s eta 0:00:08\n",
      "   ------------------------------------ --- 340.5/376.0 MB 5.1 MB/s eta 0:00:07\n",
      "   ------------------------------------ --- 342.4/376.0 MB 5.1 MB/s eta 0:00:07\n",
      "   ------------------------------------ --- 343.4/376.0 MB 5.1 MB/s eta 0:00:07\n",
      "   ------------------------------------ --- 345.2/376.0 MB 5.1 MB/s eta 0:00:07\n",
      "   ------------------------------------ --- 346.6/376.0 MB 5.1 MB/s eta 0:00:06\n",
      "   ------------------------------------- -- 347.9/376.0 MB 5.0 MB/s eta 0:00:06\n",
      "   ------------------------------------- -- 350.0/376.0 MB 5.0 MB/s eta 0:00:06\n",
      "   ------------------------------------- -- 351.3/376.0 MB 5.0 MB/s eta 0:00:05\n",
      "   ------------------------------------- -- 352.3/376.0 MB 4.9 MB/s eta 0:00:05\n",
      "   ------------------------------------- -- 353.4/376.0 MB 4.9 MB/s eta 0:00:05\n",
      "   ------------------------------------- -- 354.9/376.0 MB 4.9 MB/s eta 0:00:05\n",
      "   ------------------------------------- -- 356.3/376.0 MB 4.8 MB/s eta 0:00:05\n",
      "   -------------------------------------- - 357.3/376.0 MB 4.8 MB/s eta 0:00:04\n",
      "   -------------------------------------- - 358.1/376.0 MB 4.7 MB/s eta 0:00:04\n",
      "   -------------------------------------- - 359.9/376.0 MB 4.7 MB/s eta 0:00:04\n",
      "   -------------------------------------- - 361.2/376.0 MB 4.8 MB/s eta 0:00:04\n",
      "   -------------------------------------- - 363.3/376.0 MB 4.8 MB/s eta 0:00:03\n",
      "   -------------------------------------- - 365.4/376.0 MB 4.8 MB/s eta 0:00:03\n",
      "   ---------------------------------------  367.3/376.0 MB 4.8 MB/s eta 0:00:02\n",
      "   ---------------------------------------  369.4/376.0 MB 4.8 MB/s eta 0:00:02\n",
      "   ---------------------------------------  370.7/376.0 MB 4.9 MB/s eta 0:00:02\n",
      "   ---------------------------------------  372.8/376.0 MB 4.9 MB/s eta 0:00:01\n",
      "   ---------------------------------------  374.3/376.0 MB 4.9 MB/s eta 0:00:01\n",
      "   ---------------------------------------  375.9/376.0 MB 4.9 MB/s eta 0:00:01\n",
      "   ---------------------------------------  375.9/376.0 MB 4.9 MB/s eta 0:00:01\n",
      "   ---------------------------------------- 376.0/376.0 MB 4.8 MB/s eta 0:00:00\n",
      "Downloading absl_py-2.2.2-py3-none-any.whl (135 kB)\n",
      "Downloading astunparse-1.6.3-py2.py3-none-any.whl (12 kB)\n",
      "Downloading flatbuffers-25.2.10-py2.py3-none-any.whl (30 kB)\n",
      "Downloading gast-0.6.0-py3-none-any.whl (21 kB)\n",
      "Downloading google_pasta-0.2.0-py3-none-any.whl (57 kB)\n",
      "Downloading grpcio-1.71.0-cp312-cp312-win_amd64.whl (4.3 MB)\n",
      "   ---------------------------------------- 0.0/4.3 MB ? eta -:--:--\n",
      "   -------------- ------------------------- 1.6/4.3 MB 7.7 MB/s eta 0:00:01\n",
      "   ---------------------------------------- 4.3/4.3 MB 11.2 MB/s eta 0:00:00\n",
      "Downloading h5py-3.13.0-cp312-cp312-win_amd64.whl (3.0 MB)\n",
      "   ---------------------------------------- 0.0/3.0 MB ? eta -:--:--\n",
      "   -------------- ------------------------- 1.0/3.0 MB 5.0 MB/s eta 0:00:01\n",
      "   ---------------------------------------  2.9/3.0 MB 6.7 MB/s eta 0:00:01\n",
      "   ---------------------------------------- 3.0/3.0 MB 6.6 MB/s eta 0:00:00\n",
      "Downloading keras-3.9.2-py3-none-any.whl (1.3 MB)\n",
      "   ---------------------------------------- 0.0/1.3 MB ? eta -:--:--\n",
      "   ---------------------------------------- 1.3/1.3 MB 9.9 MB/s eta 0:00:00\n",
      "Downloading libclang-18.1.1-py2.py3-none-win_amd64.whl (26.4 MB)\n",
      "   ---------------------------------------- 0.0/26.4 MB ? eta -:--:--\n",
      "   - -------------------------------------- 1.0/26.4 MB 8.4 MB/s eta 0:00:04\n",
      "   ------ --------------------------------- 4.2/26.4 MB 11.0 MB/s eta 0:00:03\n",
      "   -------- ------------------------------- 5.5/26.4 MB 9.1 MB/s eta 0:00:03\n",
      "   ---------- ----------------------------- 6.8/26.4 MB 8.9 MB/s eta 0:00:03\n",
      "   ------------- -------------------------- 9.2/26.4 MB 9.1 MB/s eta 0:00:02\n",
      "   ----------------- ---------------------- 11.8/26.4 MB 9.7 MB/s eta 0:00:02\n",
      "   -------------------- ------------------- 13.4/26.4 MB 9.3 MB/s eta 0:00:02\n",
      "   ------------------------- -------------- 16.5/26.4 MB 10.1 MB/s eta 0:00:01\n",
      "   ------------------------- -------------- 17.0/26.4 MB 9.3 MB/s eta 0:00:02\n",
      "   ---------------------------- ----------- 18.9/26.4 MB 9.2 MB/s eta 0:00:01\n",
      "   ------------------------------- -------- 20.7/26.4 MB 9.3 MB/s eta 0:00:01\n",
      "   --------------------------------- ------ 22.3/26.4 MB 9.1 MB/s eta 0:00:01\n",
      "   ----------------------------------- ---- 23.6/26.4 MB 9.0 MB/s eta 0:00:01\n",
      "   -------------------------------------- - 25.4/26.4 MB 8.8 MB/s eta 0:00:01\n",
      "   ---------------------------------------- 26.4/26.4 MB 8.7 MB/s eta 0:00:00\n",
      "Downloading ml_dtypes-0.5.1-cp312-cp312-win_amd64.whl (210 kB)\n",
      "Downloading opt_einsum-3.4.0-py3-none-any.whl (71 kB)\n",
      "Downloading tensorboard-2.19.0-py3-none-any.whl (5.5 MB)\n",
      "   ---------------------------------------- 0.0/5.5 MB ? eta -:--:--\n",
      "   ------- -------------------------------- 1.0/5.5 MB 5.0 MB/s eta 0:00:01\n",
      "   ------------- -------------------------- 1.8/5.5 MB 3.9 MB/s eta 0:00:01\n",
      "   ---------------------------------- ----- 4.7/5.5 MB 7.3 MB/s eta 0:00:01\n",
      "   ---------------------------------------- 5.5/5.5 MB 7.0 MB/s eta 0:00:00\n",
      "Downloading termcolor-3.0.1-py3-none-any.whl (7.2 kB)\n",
      "Downloading Markdown-3.7-py3-none-any.whl (106 kB)\n",
      "Downloading tensorboard_data_server-0.7.2-py3-none-any.whl (2.4 kB)\n",
      "Downloading werkzeug-3.1.3-py3-none-any.whl (224 kB)\n",
      "Downloading namex-0.0.8-py3-none-any.whl (5.8 kB)\n",
      "Downloading optree-0.14.1-cp312-cp312-win_amd64.whl (306 kB)\n",
      "Installing collected packages: namex, libclang, flatbuffers, werkzeug, termcolor, tensorboard-data-server, optree, opt-einsum, ml-dtypes, markdown, h5py, grpcio, google-pasta, gast, astunparse, absl-py, tensorboard, keras, tensorflow\n",
      "Successfully installed absl-py-2.2.2 astunparse-1.6.3 flatbuffers-25.2.10 gast-0.6.0 google-pasta-0.2.0 grpcio-1.71.0 h5py-3.13.0 keras-3.9.2 libclang-18.1.1 markdown-3.7 ml-dtypes-0.5.1 namex-0.0.8 opt-einsum-3.4.0 optree-0.14.1 tensorboard-2.19.0 tensorboard-data-server-0.7.2 tensorflow-2.19.0 termcolor-3.0.1 werkzeug-3.1.3\n"
     ]
    }
   ],
   "source": [
    "!pip install tensorflow"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.preprocessing.text import Tokenizer\n",
    "\n",
    "tokenizer = Tokenizer(num_words=15, oov_token='<OOV>')\n",
    "\n",
    "tokenizer.fit_on_texts(preprocessed_sentences)\n",
    "\n",
    "tokenizer.word_index    # corpus의 모든 단어를 대상으로 생성"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{1: '<OOV>',\n",
       " 2: 'prince',\n",
       " 3: 'little',\n",
       " 4: 'pilot',\n",
       " 5: 'rose',\n",
       " 6: 'fox',\n",
       " 7: 'young',\n",
       " 8: 'planet',\n",
       " 9: 'earth',\n",
       " 10: 'story',\n",
       " 11: 'plane',\n",
       " 12: 'meets',\n",
       " 13: 'asteroid',\n",
       " 14: 'lessons',\n",
       " 15: 'love',\n",
       " 16: 'importance',\n",
       " 17: 'written',\n",
       " 18: 'antoine',\n",
       " 19: 'saint-exupéry',\n",
       " 20: 'poetic',\n",
       " 21: 'tale',\n",
       " 22: 'travels',\n",
       " 23: 'home',\n",
       " 24: 'begins',\n",
       " 25: 'stranded',\n",
       " 26: 'sahara',\n",
       " 27: 'desert',\n",
       " 28: 'crashes',\n",
       " 29: 'trying',\n",
       " 30: 'fix',\n",
       " 31: 'mysterious',\n",
       " 32: 'boy',\n",
       " 33: 'comes',\n",
       " 34: 'small',\n",
       " 35: 'called',\n",
       " 36: 'b-612',\n",
       " 37: 'lives',\n",
       " 38: 'alone',\n",
       " 39: 'loves',\n",
       " 40: 'deeply',\n",
       " 41: 'recounts',\n",
       " 42: 'journey',\n",
       " 43: 'describing',\n",
       " 44: 'visits',\n",
       " 45: 'several',\n",
       " 46: 'planets',\n",
       " 47: 'inhabited',\n",
       " 48: 'different',\n",
       " 49: 'character',\n",
       " 50: 'king',\n",
       " 51: 'vain',\n",
       " 52: 'man',\n",
       " 53: 'drunkard',\n",
       " 54: 'businessman',\n",
       " 55: 'geographer',\n",
       " 56: 'encounters',\n",
       " 57: 'learns',\n",
       " 58: 'valuable',\n",
       " 59: 'responsibility',\n",
       " 60: 'nature',\n",
       " 61: 'adult',\n",
       " 62: 'behavior',\n",
       " 63: 'various',\n",
       " 64: 'creatures',\n",
       " 65: 'including',\n",
       " 66: 'teaches',\n",
       " 67: 'relationships',\n",
       " 68: 'taming',\n",
       " 69: 'means',\n",
       " 70: 'building',\n",
       " 71: 'ties',\n",
       " 72: 'others',\n",
       " 73: 'famous',\n",
       " 74: 'line',\n",
       " 75: 'become',\n",
       " 76: 'responsible',\n",
       " 77: 'forever',\n",
       " 78: 'tamed',\n",
       " 79: 'resonates',\n",
       " 80: 'feelings',\n",
       " 81: 'ultimately',\n",
       " 82: 'realizes',\n",
       " 83: 'essence',\n",
       " 84: 'life',\n",
       " 85: 'often',\n",
       " 86: 'invisible',\n",
       " 87: 'seen',\n",
       " 88: 'heart',\n",
       " 89: 'sharing',\n",
       " 90: 'wisdom',\n",
       " 91: 'prepares',\n",
       " 92: 'return',\n",
       " 93: 'beloved',\n",
       " 94: 'concludes',\n",
       " 95: 'reflecting',\n",
       " 96: 'learned',\n",
       " 97: 'enduring',\n",
       " 98: 'impact',\n",
       " 99: 'friendship',\n",
       " 100: 'narrative',\n",
       " 101: 'beautifully',\n",
       " 102: 'simple',\n",
       " 103: 'yet',\n",
       " 104: 'profound',\n",
       " 105: 'exploration',\n",
       " 106: 'loss',\n",
       " 107: 'seeing',\n",
       " 108: 'beyond',\n",
       " 109: 'surface',\n",
       " 110: 'things'}"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tokenizer.index_word    # corpus의 모든 단어를 대상으로 생성"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "OrderedDict([('little', 6),\n",
       "             ('prince', 9),\n",
       "             ('written', 1),\n",
       "             ('antoine', 1),\n",
       "             ('saint-exupéry', 1),\n",
       "             ('poetic', 1),\n",
       "             ('tale', 1),\n",
       "             ('young', 2),\n",
       "             ('travels', 1),\n",
       "             ('home', 1),\n",
       "             ('planet', 2),\n",
       "             ('earth', 2),\n",
       "             ('story', 2),\n",
       "             ('begins', 1),\n",
       "             ('pilot', 4),\n",
       "             ('stranded', 1),\n",
       "             ('sahara', 1),\n",
       "             ('desert', 1),\n",
       "             ('plane', 2),\n",
       "             ('crashes', 1),\n",
       "             ('trying', 1),\n",
       "             ('fix', 1),\n",
       "             ('meets', 2),\n",
       "             ('mysterious', 1),\n",
       "             ('boy', 1),\n",
       "             ('comes', 1),\n",
       "             ('small', 1),\n",
       "             ('asteroid', 2),\n",
       "             ('called', 1),\n",
       "             ('b-612', 1),\n",
       "             ('lives', 1),\n",
       "             ('alone', 1),\n",
       "             ('rose', 3),\n",
       "             ('loves', 1),\n",
       "             ('deeply', 1),\n",
       "             ('recounts', 1),\n",
       "             ('journey', 1),\n",
       "             ('describing', 1),\n",
       "             ('visits', 1),\n",
       "             ('several', 1),\n",
       "             ('planets', 1),\n",
       "             ('inhabited', 1),\n",
       "             ('different', 1),\n",
       "             ('character', 1),\n",
       "             ('king', 1),\n",
       "             ('vain', 1),\n",
       "             ('man', 1),\n",
       "             ('drunkard', 1),\n",
       "             ('businessman', 1),\n",
       "             ('geographer', 1),\n",
       "             ('fox', 3),\n",
       "             ('encounters', 1),\n",
       "             ('learns', 1),\n",
       "             ('valuable', 1),\n",
       "             ('lessons', 2),\n",
       "             ('love', 2),\n",
       "             ('responsibility', 1),\n",
       "             ('nature', 1),\n",
       "             ('adult', 1),\n",
       "             ('behavior', 1),\n",
       "             ('various', 1),\n",
       "             ('creatures', 1),\n",
       "             ('including', 1),\n",
       "             ('teaches', 1),\n",
       "             ('relationships', 1),\n",
       "             ('importance', 2),\n",
       "             ('taming', 1),\n",
       "             ('means', 1),\n",
       "             ('building', 1),\n",
       "             ('ties', 1),\n",
       "             ('others', 1),\n",
       "             ('famous', 1),\n",
       "             ('line', 1),\n",
       "             ('become', 1),\n",
       "             ('responsible', 1),\n",
       "             ('forever', 1),\n",
       "             ('tamed', 1),\n",
       "             ('resonates', 1),\n",
       "             ('feelings', 1),\n",
       "             ('ultimately', 1),\n",
       "             ('realizes', 1),\n",
       "             ('essence', 1),\n",
       "             ('life', 1),\n",
       "             ('often', 1),\n",
       "             ('invisible', 1),\n",
       "             ('seen', 1),\n",
       "             ('heart', 1),\n",
       "             ('sharing', 1),\n",
       "             ('wisdom', 1),\n",
       "             ('prepares', 1),\n",
       "             ('return', 1),\n",
       "             ('beloved', 1),\n",
       "             ('concludes', 1),\n",
       "             ('reflecting', 1),\n",
       "             ('learned', 1),\n",
       "             ('enduring', 1),\n",
       "             ('impact', 1),\n",
       "             ('friendship', 1),\n",
       "             ('narrative', 1),\n",
       "             ('beautifully', 1),\n",
       "             ('simple', 1),\n",
       "             ('yet', 1),\n",
       "             ('profound', 1),\n",
       "             ('exploration', 1),\n",
       "             ('loss', 1),\n",
       "             ('seeing', 1),\n",
       "             ('beyond', 1),\n",
       "             ('surface', 1),\n",
       "             ('things', 1)])"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tokenizer.word_counts   # corpus의 모든 단어를 대상으로 빈도수를 반환"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[[3, 2, 1, 1, 1, 1, 1, 7, 2, 1, 1, 8, 9],\n",
       " [10, 1, 4, 1, 1, 1, 11, 1],\n",
       " [1, 1, 11, 12, 1, 7, 1, 3, 2],\n",
       " [3, 2, 1, 1, 13, 1, 1, 1, 1, 5, 1, 1],\n",
       " [1, 1, 4, 1, 1, 1, 1],\n",
       " [8, 1, 1, 1, 1, 1, 1, 1, 1, 1, 6],\n",
       " [1, 2, 1, 1, 14, 1, 1, 1, 1, 1],\n",
       " [9, 3, 2, 12, 1, 1, 1, 6, 1, 1, 1, 1, 1, 1, 1, 1],\n",
       " [6, 1, 1, 1, 1, 1, 1, 1, 2, 1, 5],\n",
       " [1, 3, 2, 1, 1, 1, 1, 1, 1, 1],\n",
       " [1, 1, 4, 1, 1, 13, 1, 5],\n",
       " [10, 1, 4, 1, 14, 1, 3, 2, 1, 1, 1],\n",
       " [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]]"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 정수 인코딩\n",
    "sequences = tokenizer.texts_to_sequences(preprocessed_sentences)\n",
    "sequences"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "pystudy_env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
